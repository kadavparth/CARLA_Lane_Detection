#! /usr/bin/env python3

import rospy
import carla
import numpy as np
from sensor_msgs.msg import PointCloud2, Image, CameraInfo
from carla_msgs.msg import CarlaActorList
import sensor_msgs.point_cloud2 as pc2
from visualization_msgs.msg import Marker
from cv_bridge import CvBridge, CvBridgeError
import cv2 

rospy.init_node("waypoints")
client = carla.Client("localhost", 2000)
client.set_timeout(2.0)
world = client.get_world()
carlaMap = world.get_map()

actors = rospy.wait_for_message("carla/actor_list", CarlaActorList)
msg = rospy.wait_for_message('/carla/ego_vehicle/rgb_front/camera_info', CameraInfo)

for actor in actors.actors:
    if actor.rolename == "ego_vehicle":
        ego_vehicle = world.get_actor(actor.id)
    elif actor.rolename == "lidar":
        lidar = world.get_actor(actor.id)
    elif actor.rolename == "rgb_front":
        camera = world.get_actor(actor.id)
    elif actor.rolename == "hero":
        hero = world.get_actor(actor.id)

K = np.array(msg.K).reshape((3,3))

class Listener:

    bridge = CvBridge()

    def __init__(self, *args, **kwargs):

        self.topic_name = topic_name
        self.data_class = data_class
        self.sub = rospy.Subscriber(self.topic_name, self.data_class, self.callback)
        self.img_sub = rospy.Subscriber('/carla/ego_vehicle/rgb_front/image', Image, self.img_cb)
        self.pub = rospy.Publisher("marker_lidar_custom", Marker, queue_size=10)

        self.pub1 = rospy.Publisher("marker_lidar_custom1", Marker, queue_size=10)

    def callback(self, msg):

        camera_transform = camera.get_transform()
        lidar_transform = lidar.get_transform()

        gen = pc2.read_points(
            msg,
            skip_nans=True,
            field_names=("x", "y", "z", "CosAngle", "ObjIdx", "ObjTag"),
        )

        points = []

        for idx, p in enumerate(gen):

            if p[5] == 10:
                points.append([p[0], p[1], p[2]])

        points = np.array(points)

        val_y_pts = np.where((points[:, 1] >= -10.0) & (points[:, 1] <= 10.0))
        val_x_pts = np.where( (points[:,0] > 0.0) )

        min_x , max_x = np.min(points[:,0][val_x_pts]), np.max(points[:,0][val_x_pts])
        min_y , max_y = np.min(points[:,1][val_y_pts]), np.max(points[:,1][val_y_pts])
        min_z, max_z = np.min(points[:,2]), np.max(points[:,2])

        x = points[:, 0][val_x_pts].mean()
        y = points[:, 1][val_y_pts].mean()
        z = points[:, 2].mean()

        self.create_marker(x, y, z, "ego_vehicle/semantic_lidar", id=1)

        lidar_to_camera = np.array([x - 2.0, y, z + 0.4]).reshape(3,1)

        x = x - 2.0 
        y = y 
        z = z + 0.4

        corners = np.array([[x - 1.5, y - 1, z + 1], 
                            [x + 1.5, y - 1, z + 1], 
                            [x + 1.5, y + 1, z + 1], 
                            [x - 1.5, y + 1.0, z + 1], 
                            [x - 1.5, y - 1, z - 1.0], 
                            [x + 1.5, y - 1, z - 1], 
                            [x + 1.5, y + 1, z - 1], 
                            [x - 1.5, y + 1.0, z - 1]] )
        

        transformation_matrix = np.array([[0, 1, 0], 
                                            [0, 0, 1], 
                                            [-1, 0, 0] ])

        opencv_transform  =  transformation_matrix @ lidar_to_camera

        pixel_coords = K @ opencv_transform

        pixel_coords[0] = pixel_coords[0]/pixel_coords[2]
        pixel_coords[1] = pixel_coords[1]/pixel_coords[2]
        
        pixel_coords = [pixel_coords[0], pixel_coords[1]]


        ## for corners 

        corners_transform = transformation_matrix @ corners.T

        pixel_corners = K @ corners_transform 

        pixel_corners /= pixel_corners[2,:]


        for i in range(pixel_corners.shape[1]):
            point_img = cv2.circle(self.img, (int(pixel_corners[0,i]), int(pixel_corners[1,i])), 3, (0,0,255), -1)

        cv2.imshow('frame',point_img)
        cv2.waitKey(1)

    def img_cb(self, msg):

        self.img = Listener.bridge.imgmsg_to_cv2(msg, 'bgr8')

    def create_marker(self, cx, cy, cz, frame, id):

        marker = Marker()
        marker.id = id
        marker.type = 1
        marker.pose.position.x = cx
        marker.pose.position.y = cy
        marker.pose.position.z = cz

        marker.pose.orientation.x = 0.0
        marker.pose.orientation.y = 0.0
        marker.pose.orientation.z = 0.0
        marker.pose.orientation.w = 1.0

        marker.scale.x = 0.5
        marker.scale.y = 0.5
        marker.scale.z = 0.5

        marker.lifetime = rospy.Duration(0.1)

        marker.header.frame_id = frame
        marker.header.stamp = rospy.Time.now()

        if id == 0:
            marker.color.r = 1.0
            marker.color.a = 1.0

            self.pub.publish(marker)

        else:
            marker.color.g = 1.0
            marker.color.a = 1.0

            self.pub1.publish(marker)


    def camera_2_world(self, vector):
    
        transformation_matrix = np.array([[0, 1, 0], 
                                        [0, 0, -1], 
                                        [1, 0, 0] ])

        camera_coords = np.dot( np.linalg.inv(transformation_matrix),np.dot( np.linalg.inv(K), vector ) )

        return camera_coords

if __name__ == "__main__":

    topic_name = "/carla/ego_vehicle/semantic_lidar"
    data_class = PointCloud2

    ls = Listener(topic_name, data_class)
    rospy.spin()
